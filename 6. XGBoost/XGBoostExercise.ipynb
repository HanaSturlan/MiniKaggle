{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X=pd.read_csv('train.csv')\n",
    "X_test_full=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same, dropping rows with missing values at target var and then separating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X,y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulating cardinality and selecting columns with low cardinality and type object\n",
    "\n",
    "low_card_cols=[cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype =='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols=[cname for cname in X_train.columns if X_train[cname].dtype in ['int64','float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns=low_card_cols + numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real=X_train[my_columns].copy()\n",
    "X_valid_real=X_valid[my_columns].copy()\n",
    "X_test=X_test_full[my_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to implement one hot encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be done in pandas or with function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_trans=SimpleImputer(strategy='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_trans=Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('num', numerical_trans, numerical_cols),\n",
    "    ('cat', categorical_trans, low_card_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model\n",
    "\n",
    "I will implement one hot encoder using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_1=XGBRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hana\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :\n",
      "16748.130190496577\n"
     ]
    }
   ],
   "source": [
    "my_pipeline=Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('model', my_model_1)\n",
    "])\n",
    "my_pipeline.fit(X_train,y_train)\n",
    "pred=my_pipeline.predict(X_valid)\n",
    "score=mean_absolute_error(y_valid, pred)\n",
    "print('MAE :')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we improve model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hana\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :\n",
      "16700.213733411816\n"
     ]
    }
   ],
   "source": [
    "my_model_2=XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "my_pipeline2=Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('model', my_model_2)\n",
    "])\n",
    "my_pipeline2.fit(X_train,y_train)\n",
    "pred2=my_pipeline2.predict(X_valid)\n",
    "score2=mean_absolute_error(y_valid, pred2)\n",
    "print('MAE :')\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we break model?\n",
    "\n",
    "We know that used estimators are about 100-1000 but if we put 1 will there must be underfitting!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :\n",
      "163382.59044574058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hana\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "my_model_3=XGBRegressor(n_estimators=1)\n",
    "my_pipeline3=Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('model', my_model_3)\n",
    "])\n",
    "my_pipeline3.fit(X_train,y_train)\n",
    "pred3=my_pipeline3.predict(X_valid)\n",
    "score3=mean_absolute_error(y_valid, pred3)\n",
    "print('MAE :')\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! We got bigger mean absoulute error which means that we have under fitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
